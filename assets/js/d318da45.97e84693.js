"use strict";(self.webpackChunkexpenses_docs=self.webpackChunkexpenses_docs||[]).push([[103],{2532:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"HLD/2.4 DesignDecisions/2 Data Engineering","title":"2 Data Engineering","description":"Absolutely \u2014 adding data engineering components to your microservices-based personal finance platform will elevate its analytical capabilities, reporting power, and scalability. Here\'s a breakdown of how you can integrate modern data engineering components (like Spark, Data Lake, ETL, pipelines, etc.) in a real-world, enterprise-style architecture.","source":"@site/docs/2. HLD/2.4 DesignDecisions/2 Data Engineering.md","sourceDirName":"2. HLD/2.4 DesignDecisions","slug":"/HLD/2.4 DesignDecisions/2 Data Engineering","permalink":"/expenses-docs/docs/HLD/2.4 DesignDecisions/2 Data Engineering","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/2. HLD/2.4 DesignDecisions/2 Data Engineering.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"1 Camunda or Camel Use Cases","permalink":"/expenses-docs/docs/HLD/2.4 DesignDecisions/1 Camunda or Camel Use Cases"},"next":{"title":"ErrorResponse","permalink":"/expenses-docs/docs/LLD/ErrorResponse"}}');var i=r(4848),t=r(8453);const a={},l=void 0,o={},d=[{value:"\u2705 Use Cases for Data Engineering in This Platform",id:"-use-cases-for-data-engineering-in-this-platform",level:2},{value:"\ud83e\uddf1 Data Engineering Architecture Additions",id:"-data-engineering-architecture-additions",level:2},{value:"\ud83d\udd27 How You Can Integrate This",id:"-how-you-can-integrate-this",level:2},{value:"1. <strong>Streaming with Kafka + Kafka Connect</strong>",id:"1-streaming-with-kafka--kafka-connect",level:3},{value:"2. <strong>Data Lake Setup</strong>",id:"2-data-lake-setup",level:3},{value:"3. <strong>ETL &amp; Analytics</strong>",id:"3-etl--analytics",level:3},{value:"4. <strong>Warehousing (Optional)</strong>",id:"4-warehousing-optional",level:3},{value:"5. <strong>Observability and Monitoring</strong>",id:"5-observability-and-monitoring",level:3},{value:"\ud83e\uddea Additions to Your Stack",id:"-additions-to-your-stack",level:2},{value:"\u2705 Starter Path",id:"-starter-path",level:2},{value:"Want Help With...",id:"want-help-with",level:2}];function c(e){const n={code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Absolutely \u2014 adding ",(0,i.jsx)(n.strong,{children:"data engineering"})," components to your microservices-based personal finance platform will elevate its analytical capabilities, reporting power, and scalability. Here's a breakdown of how you can ",(0,i.jsx)(n.strong,{children:"integrate modern data engineering components"})," (like Spark, Data Lake, ETL, pipelines, etc.) in a real-world, enterprise-style architecture."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-use-cases-for-data-engineering-in-this-platform",children:"\u2705 Use Cases for Data Engineering in This Platform"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Use Case"}),(0,i.jsx)(n.th,{children:"Data Engineering Component"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Analytical dashboards, trends over time"}),(0,i.jsx)(n.td,{children:"Data Lake + Spark"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Real-time budget alerting, fraud detection"}),(0,i.jsx)(n.td,{children:"Kafka + Stream Processing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Long-term historical storage"}),(0,i.jsx)(n.td,{children:"Cloud Data Warehouse or Lakehouse"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Enrich data with ML (e.g., smart budget recommendations)"}),(0,i.jsx)(n.td,{children:"Feature Store + ETL"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Monthly PDF reports, charts"}),(0,i.jsx)(n.td,{children:"Batch ETL jobs (Airflow/Spring Batch)"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-data-engineering-architecture-additions",children:"\ud83e\uddf1 Data Engineering Architecture Additions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:" [Microservices (Kafka Producers)]\r\n           |\r\n        Kafka (Events: expense.created, account.updated, etc)\r\n           |\r\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n \u2502 Kafka Sink \u2502 \u2192\u2192\u2192 \u2502 Data Lake  \u2502 \u2190\u2190\u2190 \u2502 Batch Loader \u2502 \u2190\u2190 External Sources (CSV, APIs)\r\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n       \u2193                        \u2193\r\n  Apache Spark (ETL + Feature Engineering)\r\n       \u2193\r\n     Delta Lake / Iceberg Table\r\n       \u2193\r\n   \u2192\u2192 BI Tools / Dashboards / Reports\r\n   \u2192\u2192 ML Pipelines (Recommender, etc.)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-how-you-can-integrate-this",children:"\ud83d\udd27 How You Can Integrate This"}),"\n",(0,i.jsxs)(n.h3,{id:"1-streaming-with-kafka--kafka-connect",children:["1. ",(0,i.jsx)(n.strong,{children:"Streaming with Kafka + Kafka Connect"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.strong,{children:"Kafka Connect"})," to write events to:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Amazon S3 / Google Cloud Storage / Azure Blob"}),"\n",(0,i.jsx)(n.li,{children:"HDFS / MinIO"}),"\n",(0,i.jsx)(n.li,{children:"PostgreSQL replica"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"\ud83d\udca1 Recommended Sink Connectors:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"Confluent S3 Sink Connector"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"JDBC Sink Connector"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"Elasticsearch Sink"})}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"2-data-lake-setup",children:["2. ",(0,i.jsx)(n.strong,{children:"Data Lake Setup"})]}),"\n",(0,i.jsxs)(n.p,{children:["Use a ",(0,i.jsx)(n.strong,{children:"cloud-native data lake"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\ud83d\udfe2 ",(0,i.jsx)(n.strong,{children:"Amazon S3 + AWS Glue"})]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udd35 ",(0,i.jsx)(n.strong,{children:"Google Cloud Storage + BigQuery"})]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udd34 ",(0,i.jsx)(n.strong,{children:"Azure Data Lake Gen2 + Synapse"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Or a local equivalent:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MinIO"})," or ",(0,i.jsx)(n.strong,{children:"HDFS"})," for dev"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"3-etl--analytics",children:["3. ",(0,i.jsx)(n.strong,{children:"ETL & Analytics"})]}),"\n",(0,i.jsx)(n.p,{children:"Use:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Apache Spark"})," for batch ETL (can run on Docker, YARN, or Kubernetes)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Apache Airflow"})," for orchestration of ETL DAGs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Spring Batch"})," for simple batch jobs in the same tech stack"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"dbt (Data Build Tool)"})," for transformations if using a data warehouse"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"ETL jobs:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Normalize budget + expense data"}),"\n",(0,i.jsx)(n.li,{children:"Join with metadata (tags, accounts)"}),"\n",(0,i.jsx)(n.li,{children:"Create dimension + fact tables"}),"\n",(0,i.jsx)(n.li,{children:"Generate aggregate reports"}),"\n",(0,i.jsxs)(n.li,{children:["Store in ",(0,i.jsx)(n.strong,{children:"Delta Lake"})," or ",(0,i.jsx)(n.strong,{children:"Parquet"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"4-warehousing-optional",children:["4. ",(0,i.jsx)(n.strong,{children:"Warehousing (Optional)"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Use a warehouse to speed up analytics:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"BigQuery"}),", ",(0,i.jsx)(n.strong,{children:"Snowflake"}),", ",(0,i.jsx)(n.strong,{children:"Redshift"}),", ",(0,i.jsx)(n.strong,{children:"ClickHouse"}),", or even ",(0,i.jsx)(n.strong,{children:"PostgreSQL (OLAP setup)"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"5-observability-and-monitoring",children:["5. ",(0,i.jsx)(n.strong,{children:"Observability and Monitoring"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Track ETL runs: Airflow UI + Prometheus + Grafana"}),"\n",(0,i.jsx)(n.li,{children:"Store ETL logs in S3 / CloudWatch / Loki"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-additions-to-your-stack",children:"\ud83e\uddea Additions to Your Stack"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Tool / Service"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Stream Ingestion"}),(0,i.jsx)(n.td,{children:"Kafka, Kafka Connect"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Data Lake"}),(0,i.jsx)(n.td,{children:"S3 / MinIO / GCS / ADLS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ETL"}),(0,i.jsx)(n.td,{children:"Apache Spark + Airflow / dbt"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Warehousing"}),(0,i.jsx)(n.td,{children:"BigQuery / Snowflake / ClickHouse"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Orchestration"}),(0,i.jsx)(n.td,{children:"Airflow"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Data Quality"}),(0,i.jsx)(n.td,{children:"Great Expectations, Soda"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Visualization"}),(0,i.jsx)(n.td,{children:"Grafana, Superset, PowerBI"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ML Feature Store"}),(0,i.jsx)(n.td,{children:"Feast or custom Delta Table"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-starter-path",children:"\u2705 Starter Path"}),"\n",(0,i.jsx)(n.p,{children:"If you\u2019re beginning, I recommend:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Publish Kafka events from your services"})," (already happening)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use Kafka Connect \u2192 write to S3 or MinIO as data lake"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Run Apache Spark batch jobs daily to process raw data"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visualize outputs in Grafana or Superset"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Later, add Airflow/DAGs to automate everything."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"want-help-with",children:"Want Help With..."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\ud83d\udee0 A sample Spark job that processes budgets and expenses from Kafka?"}),"\n",(0,i.jsx)(n.li,{children:"\ud83d\udce6 Docker Compose or Kubernetes stack with Kafka, Spark, MinIO?"}),"\n",(0,i.jsx)(n.li,{children:"\ud83e\uddf1 Building a Lakehouse architecture using Delta Lake or Apache Iceberg?"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Let me know and I\u2019ll generate that for you."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>l});var s=r(6540);const i={},t=s.createContext(i);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);